{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to 16-745: Optimal Control and Reinforcement Learning at Carnegie Mellon University!","text":"<p>Piazza Canvas Gradescope Github YouTube</p>"},{"location":"#course-description","title":"Course Description","text":"<p>This is a course about how to make robots move through and interact with their environment with speed, efficiency, and robustness. We will survey a broad range of topics from nonlinear dynamics, linear systems theory, classical optimal control, numerical optimization, state estimation, system identification, and reinforcement learning. The goal is to provide students with hands-on experience applying each of these ideas to a variety of robotic systems so that they can use them in their own research.</p> <p>Prerequisites: Strong linear algebra skills, experience with a high-level programming language like Python, MATLAB, or Julia, and basic familiarity with ordinary differential equations.</p>"},{"location":"#teaching-staff","title":"Teaching StaffZachary ManchesterJJ LeeArun BishopFausto VegaJohn ZhangAshley Kline","text":"<p>              Instructor  zacm@cmu.edu </p> <p>              Head Teaching Assistant  jeonghunlee@cmu.edu </p> <p>              Teaching Assistant  arunleob@cmu.edu </p> <p>              Teaching Assistant  fvega@andrew.cmu.edu </p> <p>              Teaching Assistant  johnzhang@cmu.edu </p> <p>              Teaching Assistant  ankline@cmu.edu </p>"},{"location":"#logistics","title":"Logistics","text":"<ul> <li>Lectures will be held Tuesdays and Thursdays 12:30-1:50 PM EST in GHC 4401. Lectures will also be live streamed on zoom and recorded for later viewing. The Zoom links for lectures and office hours are available on Piazza and Canvas.</li> </ul> <ul> <li>Office hours, lecture schedule, and deadlines can be found on the course calendar here</li> <li>Homework assignments will be due on Thursdays 11:59 PM EST, two weeks after they are assigned.</li> <li>Quizzes are released every Friday, due the following Tuesday at 11:59 PM EST.</li> <li>GitHub will be used to distribute assignments and GradeScope will be used for submissions.</li> <li>Piazza will be used for general discussion and Q&amp;A outside of class and office hours.</li> <li>There will be no exams. Instead, students will form groups of up to five to complete a project on a topic of their choice.</li> </ul>"},{"location":"#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this course, students should be able to do the following:</p> <ol> <li>Analyze the stability of dynamical systems</li> <li>Design LQR controllers that stabilize equilibria and trajectories</li> <li>Use offline trajectory optimization to design trajectories for nonlinear systems</li> <li>Use online convex optimization to implement model-predictive control</li> <li>Understand the effects of stochasticity and model uncertainty</li> <li>Directly optimize feedback policies when good models are unavailable</li> </ol>"},{"location":"#learning-resources","title":"Learning Resources","text":"<p>There is no textbook required for this course. Video recordings of lectures and lecture notes will be posted online. Additional references for further reading will be provided with each lecture. Relavent (free) background material is available in the background section of this website.</p>"},{"location":"#homework","title":"Homework","text":"<p>Four homeworks will be assigned during the semester. Students will have at least two weeks to complete each assignment. All homework will be distributed and collected using GitHub. Solutions and grades will be returned within one week of homework due dates.</p>"},{"location":"#grading","title":"Grading","text":"<p>Grading will be based on:</p> Weight Criteria 50% Project 40% Homework 5% Quizzes 5% Participation <p>Attendance during lectures is not required to earn a full participation grade. Students can also participate through any combination of office hours, Piazza discussions, project presentations, and by offering constructive feedback about the course to the instructors.</p>"},{"location":"#project-guidelines","title":"Project Guidelines","text":"<p>Students should work in groups of 1--5 to complete a substantial final project. The goal is for students to apply the coarse content to their own research. Project proposals will be solicited on the first homework and topics will be selected in consultation with the instructors.</p> <p>Project grades will be based on a short presentation given during the last week of class and a final report submitted via Google drive by May 10 Anywhere on Earth. Reports should be written in the form of a 6 page (plus references) ICRA or IROS conference paper using the standard two-column IEEE format. Sections should include an abstract, introduction and/or background to motivate your problem, 2--3 main technical sections on your contributions, conclusions, and references. Grading will be based on the following criteria:</p> Weight Criteria 10% Class presentation 10% Adherence to IEEE formatting and length requirements 10% Innovation &amp; Creativity: Is what you did new/cool/interesting? Convince me. 30% Clarity of presentation: Can I understand what you did from your writing + plots? 40% Technical correctness: Are your results reasonable? Is your code correct?"},{"location":"#course-policies","title":"Course Policies","text":"<p>Late Homework: Students are allowed a budget of 6 late days for turning in homework with no penalty throughout the semester. They may be used together on one assignment, or separately on multiple assignments. Beyond these six days, no other late homework will be accepted.</p> <p>Accommodations for Students with Disabilities: If you have a disability and are registered with the Office of Disability Resources, I encourage you to use their online system to notify me of your accommodations and discuss your needs with me as early in the semester as possible. I will work with you to ensure that accommodations are provided as appropriate. If you suspect that you may have a disability and would benefit from accommodations but are not yet registered with the Office of Disability Resources, I encourage you to contact them at access@andrew.cmu.edu.</p> <p>Statement of Support for Students' Health &amp; Well-Being: Take care of yourself. Do your best to maintain a healthy lifestyle this semester by eating well, exercising, avoiding drugs and alcohol, getting enough sleep, and taking some time to relax. This will help you achieve your goals and cope with stress.</p> <p>If you or anyone you know experiences any academic stress, difficult life events, or feelings like anxiety or depression, we strongly encourage you to seek support. Counseling and Psychological Services (CaPS) is here to help: call 412-268-2922 and visit http://www.cmu.edu/counseling. Consider reaching out to a friend, faculty, or family member you trust for help getting connected to the support that can help.</p> <p>If you or someone you know is feeling suicidal or in danger of self-harm, call someone immediately, day or night:</p> <p>CaPS: 412-268-2922</p> <p>Re:solve Crisis Network: 888-796-8226</p> <p>If the situation is life threatening, call the police:</p> <p>On campus: CMU Police: 412-268-2323</p> <p>Off campus: 911</p> <p>If you have questions about this or your coursework, please let me know. Thank you, and have a great semester.</p>"},{"location":"#schedule","title":"Schedule","text":"<p>This is subject to change. HW deadlines will be updated as the semester progresses.</p> Week Dates Topics Assignments 1 Jan 14  Jan 16 Course Overview, &amp; Dynamics Intro  Stability, Discrete-Time Dynamics Survey  HW0 Out 2 Jan 21  Jan 23 Optimization Intro  Numerical Optimization Pt. 1 Quiz 1 Due  HW0 Due, HW1 Out 3 Jan 28  Jan 30 Numerical Optimization Pt. 2 &amp; Optimal Control Intro  Regularization &amp; Merit Functions Quiz 2 Due  4 Feb 4  Feb 6 Pontryagin &amp; Shooting Methods  LQR in 3 Ways Quiz 3 Due  HW1 Due, HW2 Out 5 Feb 11  Feb 13 Dynamic Programming &amp; Intro to Convexity  Convex Model-Predictive Control Quiz 4 Due  6 Feb 18  Feb 20 Intro to Nonlinear Trajectory Optimization  Differential Dynamic Programming &amp; iLQR Quiz 5 Due  HW2 Due, HW3 Out 7 Feb 25  Feb 27 No Class  Direct Trajectory Optimization, Collocation, &amp; SQP Quiz 6 Due  8 Mar 3  Mar 5 No Class No Class 9 Mar 11  Mar 13 Attitude Intro: SO(3) &amp; Quaternions  Optimizing with Attitude 10 Mar 18  Mar 20 LQR with Attitude, Quadrotors, &amp; Contact Intro  Trajectory Optimization for Hybrid Systems Quiz 7 Due  HW3 Due, HW4 Out 11 Mar 25  Mar 27 Data-Driven Methods &amp; Iterative Learning Control  Stochastic Optimal Control &amp; LQG Quiz 8 Due  12 Apr 1  Apr 3 Robust Control &amp; Minimax DDP  No Class Quiz 9 Due  13 Apr 8  Apr 10 Practical Tips &amp; Tricks, RL from an Optimal Control Perspective  Case Study: How to Drive a Car Quiz 10 Due  HW4 Due 14 Apr 15  Apr 17 Case Study: How to Land a Rocket  Case Study: How to Walk 15 Apr 22  Apr 24 Project Presentations  Project Presentations"},{"location":"background/","title":"Background","text":""},{"location":"background/#linear-algebra","title":"Linear Algebra","text":"Resource Description Stanford CS229 Linear Algebra Review A great general purpose linear algebra primer. Matrix Cookbook Good resource for looking various linear algebra things up, no proofs. 3Blue1Brown Essence of Linear Algebra Videos detailing what linear algebra actually \"looks\" like. Convex Optimization (Appendix A) Appendix A is math background for optimization."},{"location":"background/#linear-systems","title":"Linear Systems","text":"Resource Description Stanford EE263 Introduction to linear dynamical systems and linear algebra. Tom Kailath's Linear Systems Classic book on linear systems, no PDF though."},{"location":"background/#optimization","title":"Optimization","text":"Resource Description Numerical Optimization, Nocedal and Wright The best book for general purpose (nonconvex) optimization. Implementation/algorithmic details on many common solution methods for convex and nonconvex problems. Interior point methods, active set methods, SQP, quasi-Newton methods. Convex Optimization Stephen Boyd's book, the Bible for Convex optimization. CMU Convex Lectures Ryan Tibshirani's convex lecture slides. Stanford Convex Lectures Stephen Boyd's lecture slides. PDIP QP Solver CVXGEN paper with all of the great implementation details for a classic primal-dual interior point (PDIP) method for solving quadratic programs (QPs). CVXOPT Documentation All the implementation details for convex conic solvers. Algorithms for Optimization Common gradient-based and derivative-free optimization algorithms in Julia. Calculus of Variations and Optimal Control Contains classic optimal control ideas."},{"location":"course_calendar/","title":"Course Calendar","text":"<p>The Zoom links for attending virtually are available on Piazza and Canvas.</p>"},{"location":"homeworks/","title":"Homeworks","text":""},{"location":"homeworks/#assignments","title":"Assignments","text":"Homework Solutions Topics Due Date Assignment 0 Solution 0 Julia Warm Up, Differentiation, Newton's Method 01/23/2025, 11:59 PM EST Assignment 1 Solution 1 Integrators, Equality and Inequality Constrained Optimization 02/6/2025, 11:59 PM EST Assignment 2 Solution 2 LQR, TVLQR, and Convex MPC 02/20/2025, 11:59 PM EST Assignment 3 Solution 3 NLP and iLQR 03/20/2025, 11:59 PM EST Assignment 4 TBA ILC &amp; Hybrid Traj Opt 04/10/2025, 11:59 PM EST"},{"location":"homeworks/#submission-instructions","title":"Submission Instructions","text":"<p>Submit all HWs as PDFs of your completed Jupyter Notebooks in Gradescope. Please review all the checklist items and instructions below:</p>"},{"location":"homeworks/#checklist","title":"Checklist","text":"<p>Before you submit your completed homework PDF, remember to complete all the checklist items below:</p> <ul> <li>Make sure text and code, including special characters, are completely legible.</li> <li>Make sure code is completely visible (i.e., no cropped lines). If we can't see it, then we can't grade it... Look at section below for details on how to remedy this.</li> <li>Make sure plots and unit tests have been outputted and rendered properly. Meshcat visuals are exempt.</li> <li>DO NOT ALTER UNIT TEST CASES. We check and can tell...</li> <li>Assign questions to each respective page of your PDF in Gradescope# Homeworks</li> </ul>"},{"location":"homeworks/#assignments_1","title":"Assignments","text":"Homework Solutions Topics Due Date Assignment 0 TBA Julia Warm Up, Differentiation, Newton's Method 01/23/2025, 11:59 PM EST"},{"location":"homeworks/#submission-instructions_1","title":"Submission Instructions","text":"<p>Submit all HWs as PDFs of your completed Jupyter Notebooks in Gradescope. Please review all the checklist items and instructions below:</p>"},{"location":"homeworks/#checklist_1","title":"Checklist","text":"<p>Before you submit your completed homework PDF, remember to complete all the checklist items below:</p> <ul> <li>Make sure text and code, including special characters, are completely legible.</li> <li>Make sure code is completely visible (i.e., no cropped lines). If we can't see it, then we can't grade it... Look at section below for details on how to remedy this.</li> <li>Make sure plots and unit tests have been outputted and rendered properly. Meshcat visuals are exempt.</li> <li>DO NOT ALTER UNIT TEST CASES. We check and can tell...</li> <li>Assign questions to each respective page of your PDF in Gradescope, including the text of the problem.</li> </ul>"},{"location":"homeworks/#fixing-cropped-code","title":"Fixing Cropped Code","text":"<p>If your code is cropped in the PDF, then there are multiple remedies for this:</p> <ol> <li>Split line around binary operator (e.g., +): <pre><code>L_grad = FD.gradient(f, x) +\n                transpose(FD.jacobian(c, x))*\u03bb\n</code></pre></li> <li>Split line around parenthesis: <pre><code>L_grad = (FD.gradient(f, x)\n                + transpose(FD.jacobian(c, x))*\u03bb)\n</code></pre></li> <li>Split line after assignment operator (e.g., =): <pre><code>L_grad = \n    FD.gradient(f, x) + transpose(FD.jacobian(c, x))*\u03bb\n</code></pre></li> <li> <p>Combine 1-3 to split into more lines: <pre><code>L_grad = \n    FD.gradient(f, x) +\n    transpose(FD.jacobian(c, x))*\u03bb\n</code></pre></p> </li> <li> <p>Assign terms to more variables: <pre><code>cost_grad = FD.gradient(f, x)\nconstraint_jac_T = transpose(FD.jacobian(c, x))\n\nL_grad = cost_grad + constraint_jac_T*\u03bb\n</code></pre></p> </li> </ol>"},{"location":"homeworks/#export-to-pdf","title":"Export to PDF","text":"<p>Feel free to use any method you'd like to export your Jupyter notebook as a PDF (with all checklist items completed). </p> <p>We recommend the following method of converting your Jupyter notebook to a PDF because it requires no additional installs (hopefully). It's slightly involved, but it is the most consistent in our experience.</p> <ol> <li>Open the Jupyter notebook in your favorite web browser (not VS Code) with IJulia.</li> <li>Go through the submission checklist, and make sure all relevant items are completed.</li> <li>In the top left corner of the Jupyter menu bar, do <code>File -&gt; Save and Export Notebook As -&gt; HTML</code>. It should download an HTML file.</li> <li>Open the downloaded HTML file in your favorite web browser.</li> <li>Open up the browser's print menu and select <code>Save as PDF</code>.</li> <li>Save and combine PDFs. </li> <li>Submit on Gradescope, and make sure to assign the right pages to all questions.</li> </ol>"},{"location":"homeworks/#others","title":"Others","text":"<p>If HTML to PDF does not work, feel free to try other methods: https://mljar.com/blog/jupyter-notebook-pdf/., including the text of the problem.</p>"},{"location":"homeworks/#fixing-cropped-code_1","title":"Fixing Cropped Code","text":"<p>If your code is cropped in the PDF, then there are multiple remedies for this:</p> <ol> <li>Split line around binary operator (e.g., +): <pre><code>L_grad = FD.gradient(f, x) +\n                transpose(FD.jacobian(c, x))*\u03bb\n</code></pre></li> <li>Split line around parenthesis: <pre><code>L_grad = (FD.gradient(f, x)\n                + transpose(FD.jacobian(c, x))*\u03bb)\n</code></pre></li> <li>Split line after assignment operator (e.g., =): <pre><code>L_grad = \n    FD.gradient(f, x) + transpose(FD.jacobian(c, x))*\u03bb\n</code></pre></li> <li> <p>Combine 1-3 to split into more lines: <pre><code>L_grad = \n    FD.gradient(f, x) +\n    transpose(FD.jacobian(c, x))*\u03bb\n</code></pre></p> </li> <li> <p>Assign terms to more variables: <pre><code>cost_grad = FD.gradient(f, x)\nconstraint_jac_T = transpose(FD.jacobian(c, x))\n\nL_grad = cost_grad + constraint_jac_T*\u03bb\n</code></pre></p> </li> </ol>"},{"location":"homeworks/#export-to-pdf_1","title":"Export to PDF","text":"<p>Feel free to use any method you'd like to export your Jupyter notebook as a PDF (with all checklist items completed). </p> <p>We recommend the following method of converting your Jupyter notebook to a PDF because it requires no additional installs (hopefully). It's slightly involved, but it is the most consistent in our experience.</p> <ol> <li>Open the Jupyter notebook in your favorite web browser (not VS Code) with IJulia.</li> <li>Go through the submission checklist, and make sure all relevant items are completed.</li> <li>In the top left corner of the Jupyter menu bar, do <code>File -&gt; Save and Export Notebook As -&gt; HTML</code>. It should download an HTML file.</li> <li>Open the downloaded HTML file in your favorite web browser.</li> <li>Open up the browser's print menu and select <code>Save as PDF</code>.</li> <li>Save and combine PDFs. </li> <li>Submit on Gradescope, and make sure to assign the right pages to all questions.</li> </ol>"},{"location":"homeworks/#others_1","title":"Others","text":"<p>If HTML to PDF does not work, feel free to try other methods: https://mljar.com/blog/jupyter-notebook-pdf/.</p>"},{"location":"lectures/","title":"2025","text":"<p>Lectures will be streamed live on Zoom, through the link available from Piazza and Canvas. After the lecture, the recording and all related materials will be made available here.</p> Lecture Topics Materials 1 Introduction and Dynamics video, slides 2 Dynamics Discretization &amp; Stability video, slides Optimization 3 Optimization Pt. 1 video, slides 4 Optimization Pt. 2 video, slides 5 Optimization Pt. 3 video, slides 6 Regularization, Merit Functions, and Control History video, slides Optimal Control 7 Deterministic Optimal Control and Pontryagin video, slides 8 LQR in 3 Ways video, slides 9 Controllability &amp; Dynamic Programming video, slides 10 Convex MPC video, slides 11 Nonlinear Trajectory Optimization video, slides 12 Differential Dynamic Programming video, slides 13 Direct Trajectory Optimization video, slides Rotations 14 Intro to 3D Rotations video, slides 15 Optimizing Rotations video, slides 16 LQR with Quaternions and Quadrotors video, slides Special Topics 17 Hybrid Systems and Legged Robots video, slides 18 Iterative Learning Control video, slides 19 Stochastic Optimal Control and LQG video, slides 20 How to Walk video, slides"},{"location":"lectures/#2024","title":"2024","text":"Lecture Topics Materials 1 Introduction and Dynamics video, slides 2 Dynamics Discretization &amp; Stability video, slides Optimization 3 Optimization Pt. 1 video, slides 4 Optimization Pt. 2 video, slides 5 Optimization Pt. 3 video, slides Optimal Control 6 Deterministic Optimal Control Intro video, slides 7 The Linear Quadratic Regulator Three Ways video, slides 8 Controllability and Dynamic Programming video, slides 9 Convex Model-Predictive Control video, slides 10 Nonlinear Trajectory Optimization video, slides 11 Differential Dynamic Programming video, slides 12 Direct Trajectory Optimization video, slides Rotations 13 Dealing with 3D Rotations video, slides 14 Optimizing Rotations video, slides 15 LQR with Quaternions and Quadrotors (2023 lecture) video, slides, code Special Topics 16 Hybrid Systems and Legged Robots (2023 lecture) video, slides, code 17 Iterative Learning Control video, slides, code 18 Stochastic Optimal Control and LQG video, slides, code 19 Kalman Filters and Duality video, slides, code 20 Convex Relaxation and Landing Rockets video, slides, code 21 Legged Robots and How to Walk with QPs video, slides, code 22 Autonomous Driving video, slides, code 23 Calculus of Variations and Physics as Optimal Control video, slides, code"},{"location":"lectures/#2023","title":"2023","text":"Lecture Topics Materials 1 Introduction and Dynamics video, slides, code 2 Dynamics Discretization &amp; Stability video, slides, code Optimization 3 Optimization Pt. 1 video, slides, code 4 Optimization Pt. 2 video, slides, code 5 Optimization pt. 3 video, slides, code Optimal Control 6 Deterministic Optimal Control Intro video, slides, code 7 The Linear Quadratic Regulator Three Ways video, slides, code 8 Controllability and Dynamic Programming video, slides, code 9 Convex Model-Predictive Control video, slides, code 10 Nonlinear Trajectory Optimization video, slides, code 11 Differential Dynamic Programming video, slides, code 12 Direct Trajectory Optimization video, slides, code Rotations 13 Dealing with 3D Rotations video, slides, code 14 Optimizing Rotations video, slides, code 15 LQR with Quaternions and Quadrotors video, slides, code Special Topics 16 Hybrid Systems and Legged Robots video, slides, code 17 Iterative Learning Control video, slides, code 18 Stochastic Optimal Control and LQG video, slides, code 19 Kalman Filters and Duality video, slides, code 20 Robust Control and Minimax Optimization video, slides, code 21 Convex Relaxation and Landing Rockets video, slides, code 22 Legged Robots and How to Walk with QPs video, slides, code 23 Autonomous Driving and Game Theory video, slides, code 24 Reinforcement Learning video, slides, code"},{"location":"lectures/#useful-links","title":"Useful Links","text":"<p>2024 recitation Youtube playlist</p> <p>Github Repo</p>"},{"location":"piazza/","title":"Piazza","text":"<p>Enroll in Piazza here.</p>"},{"location":"quizzes/","title":"Quizzes","text":"Week Materials 1 questions 2 questions 3 questions 4 questions 5 questions 6 questions 7 questions 8 questions 9 questions"},{"location":"recitations/","title":"Recitations","text":""},{"location":"recitations/#2025","title":"2025","text":"<p>There will be no official recitations for 2025. Please feel free to refer to previous years' for additional material.</p>"},{"location":"recitations/#2024","title":"2024","text":"Recitation # Topics Materials 1 Linear Systems, Taylor Series video, slides 2 Derivatives, Constrained Optimization video, slides 3 KKT Conditions, Augmented Lagrangian video, slides 4 Intro to LQR and Convex.jl video, slides 5 Dynamic Programming and MPC video, slides 6 Trajectory Optimization video, slides 7 Attitude Part 1 video, slides 8 Attitude Part 2 video, slides 9 Sparse Trajectory Optimization video, slides"},{"location":"recitations/#useful-links","title":"Useful Links","text":"<p>Youtube recitation playlist</p> <p>Github Repo</p>"},{"location":"recitations/#2023","title":"2023","text":"Recitation # Topics Materials 1 Linear Systems, Derivatives, Taylor Series video, slides 2 Newton's method, constrained optimization video, slides 3 KKT Conditions, Augmented Lagrangian video, slides 4 Intro to LQR video, slides 5 HW1 review, Convex.jl tutorial video,       code 6 MPC, HW2 video, slides, code 7 Rotation Matrices, Quaternions, Planning with Attitude video, slides 8 LQR, Discretization, Linearization video, slides, code 9 DIRCOL, iLQR, HW3 video, slides 10 Differentiable Collision Detection video, slides, code"},{"location":"recitations/#useful-links_1","title":"Useful Links","text":"<p>Youtube recitation playlist</p> <p>Github Repo</p>"},{"location":"course_notes/notes_home/","title":"Notes home","text":"<p>THIS IS A WORK IN PROGRESS</p> <p>The section of the website will be updated with markdown/latex version of the lectures as the semester progresses. To view them, select a section from the navigation on the left hand side of this page. </p>"},{"location":"course_notes/dynamics/lec1/","title":"1. Continuous-Time Dynamics &amp; Equilibria","text":""},{"location":"course_notes/dynamics/lec1/#topics-covered","title":"Topics Covered","text":"<ul> <li>Introduction</li> <li>Motivating Example (Pendulum)</li> <li>Continuous-Time Dynamics</li> <li>Equilibria</li> </ul>"},{"location":"course_notes/dynamics/lec1/#introduction","title":"Introduction","text":"<p>To start things off, we're going to go through some background material. Specifically, we're first going to provide a crash course on dynamics, which defines the behavior of many robotics systems that we will later attempt to \"control\" to do what we want. Before we do \"optimal control,\" we need to understand what we're going to control and what it means to control a robot.</p> <p>Disclaimer: This course will have an emphasis on robotics applications, specifically mechanical systems, but many of the methods are applicable to other types of systems such as chemical processes, which is where optimal control actually originated from.</p> <p>We'll begin with a high-level overview of continuous-time dynamics, equilibria, and stability to provide a background to those unfamiliar with topics like dynamics and differential equations. This will provide a basic foundation to describe how robotic systems move and interact with their environment. In later lectures, we will learn how to discretize them to make them useful for computers (e.g., our future controllers).</p>"},{"location":"course_notes/dynamics/lec1/#motivating-example-pendulum","title":"Motivating Example (Pendulum)","text":"<p>Let's start with a real-life example: a pendulum, the world's simplest nonlinear dynamical system (or robot),</p> <p></p> <p>where we have a point mass of mass \\(m\\) subject to gravity, \\(g\\), while being suspended by a massless rod of length \\(l\\) that can swing about a pivot point.</p> <p>If we want to describe the motion of the pendulum, we need to:</p> <ol> <li>Define scalar variables that represent/parameterize the system,</li> <li>Describe how those variables evolve to explain the system's behavior.</li> </ol> <p>In the case of the pendulum, we somehow want to parameterize its swinging motion. First, we need to way to characterize where the pendulum is during the swing; one way of doing so is keeping track of the pendulum's angle, \\(\\theta\\), which gives us one variable. However, that's not enough - if we want to be able to know where the pendulum will be in the future (i.e., how it will evolve), we also need to know how fast its swinging. Therefore, let's also keep track of the pendulum's angular velocity, \\(\\dot{\\theta}\\). To be concise, we can stack our variables into a vector \\(\\in \\mathbb{R}^{2}\\) (i.e., in 2D space of real numbers):</p> \\[ x = \\begin{bmatrix}     \\theta\\\\     \\dot{\\theta} \\end{bmatrix}. \\] <p>Now, we can use those variables (along with physics) to describe how the pendulum swings in the form of a ODE (ordinary differential equation):</p> \\[ ml^{2}\\ddot{\\theta} + mgl\\sin(\\theta) = \\tau, \\] <p>where \\(\\tau \\in \\mathbb{R}\\) is the torque applied to the pendulum. Just like before with the variables, we can express this ODE in a vector form:</p> \\[ f(x, u) = \\begin{bmatrix}     \\dot{\\theta}\\\\     \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix}     \\dot{\\theta}\\\\     -\\frac{g}{l}\\sin(\\theta) + \\frac{1}{ml^{2}}u \\end{bmatrix}, \\] <p>where \\(u = \\tau\\). To provide names to everything, we call \\(x\\) the pendulum's state and \\(f(x, u)\\) the pendulum's dynamics model. </p> <p>Now, let's say we want to make the pendulum \"do something.\" Let's say we want to make it rotate counter-clockwise. Then we need to apply some sort of input to the system. In the pendulum's case, we can apply a torque (from an imaginary motor at the base) which we defined as \\(u\\). As hinted at earlier, we call \\(u\\) our control input.</p>"},{"location":"course_notes/dynamics/lec1/#continuous-time-dynamics","title":"Continuous-Time Dynamics","text":""},{"location":"course_notes/dynamics/lec1/#general-form","title":"General Form","text":"<p>While the pendulum is a nice, specific, real-life example, we need to be able to express things more generally to extend the same idea to other systems. The most general/generic way to write continuous-time dynamics for a smooth sytem is in the form,</p> \\[ \\dot{x} = f(x, u). \\] <p>Just like we did for the pendulum, we call \\(f\\) the dynamics, \\(x \\in \\mathbb{R}^{n}\\) the state (assume a vector for now), and \\(u \\in \\mathbb{R}^{m}\\) the input. From a robotics perspective, smooth means that it doesn't involve things like rigid contact that cause discontinuous/switching behaviors. We'll study this in greater detail in later lectures.</p> <p>Specifically for a mechanical system (most things in robotics), the state can be split into 2 pieces:</p> \\[ x = \\begin{bmatrix}     q\\\\     v \\end{bmatrix}, \\] <p>where \\(q\\) is called the configuration/pose and \\(v\\) is the velocity. In the case of the pendulum, the configuration would be the angle, and the velocity would be the angular velocity:</p> \\[ \\begin{align}     q &amp; = \\theta, \\\\     v &amp; = \\dot{\\theta}. \\end{align} \\] <p>NOTE: \\(q\\) is not always a vector. For example, in the case of the pendulum, we kind of lied... \\(\\theta\\) can only be between \\(0\\) and \\(2\\pi\\). Therefore, we say the \\(q \\in \\mathbb{S}^{1}\\) (i.e., in a 1D circle). If \\(\\dot{\\theta}\\) can be any real number, then what does \\(x\\) look like? HINT: it's not \\(\\mathbb{R}^{2}\\).</p>"},{"location":"course_notes/dynamics/lec1/#control-affine-systems","title":"Control-Affine Systems","text":"<p>Often times, we see common structures across so many dynamical systems that we give them labels. One kind is called control-affine systems, which is in the form,</p> \\[ \\dot{x} = f_{0}(x) + B(x)u, \\] <p>where \\(f_{0}\\) is called the drift term, and \\(B(x)\\) is known as the input Jacobian. This expression essentially just means that the dynamics is linear with respect to \\(u\\). It turns out most systems, including all mechanical systems, can be written in this form. In the case of the pendulum:</p> \\[ f_{0}(x) = \\begin{bmatrix}     \\dot{\\theta}\\\\     -\\frac{g}{l}\\sin(\\theta) \\end{bmatrix},\\quad B(x) = \\begin{bmatrix}     0\\\\     \\frac{1}{ml^{2}} \\end{bmatrix}. \\]"},{"location":"course_notes/dynamics/lec1/#manipulator-dynamics","title":"Manipulator Dynamics","text":"<p>If we get even more specific, we'll find another form that's very common in robotics. In fact, this specific form once again encompasses all mechanical systems. We call it the manipulator equation, which we write as</p> \\[ M(q)\\dot{v} + C(q, v) = B(q)u + F, \\] <p>where \\(M(q)\\) is called the mass matrix, \\(C(q, v)\\) is the dynamic bias, \\(B(q)\\) is again the input Jacobian, and \\(F\\) represents all other external forces. As we noted before, \\(q\\) is not always a vector, which implies that in a lot of cases, \\(\\dot{q} \\neq v\\). Therefore, we must generally say that</p> \\[ \\dot{q} = G(q)v. \\] <p>We call this expression the velocity kinematics, and this will show up a lot in 3D rotations (e.g., quaternions, rotation matrices, and if you're sadistic... Euler angles), which we'll study in later lectures. </p> <p>When applied to our pendulum example, the manipulator equation's terms are</p> \\[ M(q) = ml^{2}, \\quad C(q, v) = mgl\\sin(\\theta), \\quad B = I, \\quad G=I. \\] <p>Practically speaking, a lot of existing robotics toolboxes/packages will provide these terms for you so that we don't have to do heinous, complicated physics to get them - hurray!</p> <p>Remember, we still need our dynamics model to describe \\(\\dot{x}\\) (how our states evolve). Massaging the manipulator equation to do so gives us</p> \\[ \\dot{x} = f(x, u) = \\begin{bmatrix}     G(q)v\\\\     M(q)^{-1}[B(q)u + F - C] \\end{bmatrix}. \\] <p>One nice thing about this is that \\(M(q)\\) is always invertible if we make good choices for the coordinates of \\(x\\). In addition, inverting \\(M(q)\\) is the most expensive operation here, which limits the time-complexity of solving this equation to \\(O(n^{3})\\). This is good because we care about speed; our controller has to run in real-time when on an actual robot. Unfortunately, this can still be expensive for a big robot with a lot of links (e.g., humanoid), but there are smarter ways of dealing with this that can be \\(O(n)\\).</p> <p>NOTE: Practically speaking, you should almost never solve for \\(M(q)^{-1}\\) directly. As alluded to earlier, there are applicable, smart solvers/methods for solving linear systems (\\(Ax=b\\)) that can achieve \\(O(n)\\).</p>"},{"location":"course_notes/dynamics/lec1/#linear-systems","title":"Linear Systems","text":"<p>Linear systems are our most specific, but still widely-used form of modeling dynamical systems. In fact, it's hard to overstate just how important linear systems are in control theory; we can solve them exactly in closed-form, analyze their behaviors rigorously, and approximate many systems with linear models. In fact, they're so well-studied that there are whole classes/textbooks on them, but for our purposes, we'll provide a high-level overview here.</p> <p>As hinted by the name, linear systems have the form:</p> \\[ \\dot{x} = A(t)x + B(t)u. \\] <p>If \\(A(t)\\) and \\(B(t)\\) are constant (i.e., \\(A(t) = A\\), \\(B(t) = B\\)), then the system is called time invariant. The system is time varying otherwise.</p> <p>As previously mentioned, linear systems are super important in control, one of those reasons being that we often approximate nonlinear systems locally with linear ones using Taylor series:</p> \\[ \\dot{x} = f(x, u) \\quad \\Rightarrow \\quad A=\\frac{\\partial f}{\\partial x}, \\quad B = \\frac{\\partial f}{\\partial u}. \\] <p>It turns out this works surprisingly well in controls; so well that we can often design bread-and-butter controllers with the linearized model and still run it successfully in nonlinear settings (e.g., the real world). This is usually a good first step!</p> <p></p>"},{"location":"course_notes/dynamics/lec1/#equilibria","title":"Equilibria","text":""},{"location":"course_notes/dynamics/lec1/#definition","title":"Definition","text":"<p>Switching gears a little bit, let's now talk about another super important topic in dynamics, which is equilibria. Intuitively, this is a point where a system will \"remain at rest.\" Algebraically, the equilibria, \\(x_{eq}\\), are the roots of our dynamics, where</p> \\[ \\dot{x} = f(x, u) = 0. \\] <p>In the case of the pendulum, the equilibria are where our pendulum is pointing straight down and upright respectively; if we leave the pendulum at those spots, it shouldn't move. We can determine the points (i.e., the states) that correspond to the equilibria:</p> \\[ \\dot{x} = \\begin{bmatrix}     \\dot{\\theta}\\\\     -\\frac{g}{l}\\sin{\\theta} \\end{bmatrix} = \\begin{bmatrix}     0 \\\\     0 \\end{bmatrix} \\quad \\Rightarrow \\quad x_{eq} = \\begin{bmatrix}     0 \\\\     0 \\end{bmatrix}, \\begin{bmatrix}     \\pi \\\\     0 \\end{bmatrix}. \\] <p></p>"},{"location":"course_notes/dynamics/lec1/#first-control-problem","title":"First Control Problem","text":"<p>Let's use this opportunity to solve our first control problem: what \\(u\\) do we need to apply to move the equilibria to \\(\\theta = \\frac{\\pi}{2}\\)?</p> <p></p> <p>Using the expression of equilibria for our pendulum, we can solve for \\(u\\) accordingly:</p> \\[ \\begin{align}     \\dot{x} = \\begin{bmatrix}         \\dot{\\theta}\\\\         -\\frac{g}{l}\\sin{\\theta} + \\frac{1}{ml^{2}}u     \\end{bmatrix} &amp; = \\begin{bmatrix}         0 \\\\         0     \\end{bmatrix}, \\\\     \\space \\\\     \\Rightarrow \\frac{1}{ml^{2}}u &amp; = \\frac{g}{l}\\sin{\\theta}, \\\\     \\space \\\\     \\Rightarrow u &amp; = mgl. \\end{align} \\] <p>Like this pendulum example, we generally get a root-finding problem in \\(u\\):</p> \\[ f(x^{*}, u) = 0 \\]"},{"location":"course_notes/dynamics/lec1/#stability-of-equilibria","title":"Stability of Equilibria","text":"<p>Not only do we care about where the equilibria are, but also how stable they are. This is absolutely another core concept in control, so we strongly suggest you pay attention. What we're generally asking with regard to stability is the following: \"when will we stay stay 'near' an equilibrium point under perturbations?\"</p> <p>We'll demonstrate by example by looking at a made-up, stupid-looking 1D system (\\(x \\in \\mathbb{R}\\)) with no control inputs:</p> <p></p> <p>We can mark the equilibria by finding the roots, which are circled in black. Let's look at the middle one first; if we choose a point just to its right, the sign of \\(\\dot{x}\\) is negative, which is going to push us back to the equilibrium. If we choose a point on the left, then the positive \\(\\dot{x}\\) is also going to push us back towards the equilibrium. Because we'll wind up back at the equilibrium from any direction, we call the middle equilibrium point a stable equilibrium.</p> <p></p> <p>If we look at either the left or the right equilibrium, we can play the same game; if we choose a point close but to the right, the sign of \\(\\dot{x}\\) is positive, which is going to push us away from the equilibrium. A point on the left will also push us away, so no matter what, we'll be moving away from the equilibrium. As you can guess, we call the left and right equilibrium points unstable equilibria.</p> <p></p> <p>From a more mathematical standpoint, we can see that the derivatives of \\(f\\) at the equilibria determine the stability:</p> \\[ \\begin{align}     \\frac{\\partial f}{\\partial x}\\Bigg|_{x_{eq}} &amp; &lt; 0 \\quad \\Rightarrow \\quad \\text{stable}, \\\\     \\space \\\\     \\frac{\\partial f}{\\partial x}\\Bigg|_{x_{eq}} &amp; &gt; 0 \\quad \\Rightarrow \\quad \\text{unstable}. \\\\ \\end{align} \\] <p>In the case of the pendulum, we can intuitively see that the bottom and upright equilibria correspond to a stable and unstable one respectively. However, for this higher-dimensional system, how do we come up with a mathematically equivalent version? We know that the higher-dimensional equivalent to a scalar derivative is the Jacobian (\\(\\frac{\\partial f}{\\partial x}\\)), but what's the equivalent to the Jacobian being positive or negative? </p> <p>The answer lies in the eigenvalues! Let us linearize the dynamics at an equilibrium and perform an eigendecomposition of \\(\\frac{\\partial f}{\\partial x}\\):</p> \\[ \\begin{align}     \\dot{x} &amp; = \\frac{\\partial f}{\\partial x}\\Bigg|_{x_{eq}}x, \\\\     \\space \\\\     \\Rightarrow \\dot{x} &amp; = \\underbrace{\\Bigg[\\begin{smallmatrix}         | &amp; &amp; | \\\\         v_{1} &amp; \\cdots  &amp; v_{n} \\\\         | &amp; &amp; | \\\\     \\end{smallmatrix}\\Bigg]}_{T} \\underbrace{\\Bigg[\\begin{smallmatrix}     \\lambda_{1} &amp; &amp; 0 \\\\     &amp; \\ddots &amp; \\\\     0 &amp; &amp; \\lambda_{n}     \\end{smallmatrix}\\Bigg]}_{\\Lambda} \\underbrace{\\Bigg[\\begin{smallmatrix}         | &amp; &amp; | \\\\         v_{1} &amp; \\cdots  &amp; v_{n} \\\\         | &amp; &amp; | \\\\     \\end{smallmatrix}\\Bigg]^{-1}}_{T^{-1}} x \\\\     \\Rightarrow \\dot{x} &amp; = T \\Lambda T^{-1}x, \\\\     \\space \\\\     \\Rightarrow T^{-1}\\dot{x} &amp; = \\Lambda T^{-1}x, \\\\ \\end{align} \\] <p>where \\(v_{i} \\in \\mathbb{R}^{n}\\) is the \\(i\\)th eigenvector of \\(\\frac{\\partial f}{\\partial x}\\) and \\(\\lambda_{i} \\in \\mathbb{C}\\) (i.e., a complex scalar) is the corresponding eigenvalue. By relabeling the linear mapping, \\(T^{-1}x\\), as a new vector, \\(z\\), we can now analyze the system in terms of \\(z\\):</p> \\[ \\begin{align}     \\Rightarrow \\dot{z} &amp; = \\Lambda z, \\\\     \\space \\\\     \\Rightarrow \\dot{z} &amp; = \\Bigg[\\begin{smallmatrix}     \\lambda_{1} &amp; &amp; 0 \\\\     &amp; \\ddots &amp; \\\\     0 &amp; &amp; \\lambda_{n}     \\end{smallmatrix}\\Bigg]z, \\\\ \\end{align} \\] <p>then we can see that we essentially decoupled the higher-dimensional system into multiple 1D systems. Therefore we can evaluate the real parts of each eigenvalue of \\(\\frac{\\partial f}{\\partial x}\\) in a similar manner as before with the scalar case:</p> \\[ \\begin{align}     \\text{Re}\\Big(\\text{eigvals}\\Big[\\frac{\\partial f}{\\partial x}\\Big|_{x_{eq}}\\Big]\\Big) &amp; &lt; 0 \\quad \\Rightarrow \\quad \\text{stable}, \\\\     \\space \\\\     \\text{Re}\\Big(\\text{eigvals}\\Big[\\frac{\\partial f}{\\partial x}\\Big|_{x_{eq}}\\Big]\\Big) &amp; &gt; 0 \\quad \\Rightarrow \\quad \\text{unstable}. \\\\ \\end{align} \\] <p>NOTE: If any of the eigenvalues' real parts is positive, then the system is unstable. Also, remember to evaluate \\(\\frac{\\partial f}{\\partial x}\\) at the equilibrium of interest!</p> <p>Applying our stability analysis to the pendulum:</p> \\[ \\begin{align}     f(x) &amp; = \\begin{bmatrix}         \\dot{\\theta}\\\\         -\\frac{g}{l}\\sin{\\theta}     \\end{bmatrix} \\quad \\Rightarrow \\quad \\frac{\\partial f}{\\partial x} = \\begin{bmatrix}         0 &amp; 1 \\\\         -\\frac{g}{l}\\cos{\\theta} &amp; 0     \\end{bmatrix}, \\\\     \\space \\\\     \\space \\\\     \\frac{\\partial f}{\\partial x} \\Bigg|_{\\theta = \\pi} &amp; = \\begin{bmatrix}         0 &amp; 1 \\\\         \\frac{g}{l} &amp; 0     \\end{bmatrix} \\quad \\Rightarrow \\quad \\text{eigvals}\\Big(\\frac{\\partial f}{\\partial x}\\Big|_{\\theta = \\pi}\\Big) = \\pm \\sqrt{\\frac{g}{l}}, \\\\     \\space \\\\     \\frac{\\partial f}{\\partial x} \\Bigg|_{\\theta = 0} &amp; = \\begin{bmatrix}         0 &amp; 1 \\\\         -\\frac{g}{l} &amp; 0     \\end{bmatrix} \\quad \\Rightarrow \\quad \\text{eigvals}\\Big(\\frac{\\partial f}{\\partial x}\\Big|_{\\theta = 0}\\Big) = 0 \\pm i\\sqrt{\\frac{g}{l}}. \\\\ \\end{align} \\] <p>As expected, at \\(\\theta = \\pi\\), a positive real component of an eigenvalue \\(\\Big(\\sqrt{\\frac{g}{l}}\\Big)\\) exists, so the pendulum is unstable about the upright equilibrium. This matches our intuition.</p> <p>At \\(\\theta = 0\\), we see that the real components of the eigenvalues are equal to 0. This isn't in our notes - what's going on?</p> <p>In the case of the pendulum, we can see that without damping, the pendulum will just keep swinging about the bottom equilibrium. We call this behavior marginally stable.</p> <p>NOTE: In general, if \\(\\text{Re}\\Big(\\text{eigvals}\\Big[\\frac{\\partial f}{\\partial x}\\Big|_{x_{eq}}\\Big]\\Big) = 0\\), we can't say anything about the stability! It just so happens that the pendulum is marginally stable, but in general, we can't make any conclusions about the system's stability about that equilibrium. We'll have to go to fancier methods, like Lyapunov stability analysis.</p>"}]}